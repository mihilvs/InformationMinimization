{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260eea93-5468-4f7a-bf92-d9a36fb3e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, urllib.request, gzip, shutil, copy\n",
    "import networkx as nx, numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd781be-cd55-4c2f-a2c8-0e626cc65cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_influence(G, p=0.4, n_sims=1000):\n",
    "    spreads = []\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return 0.0\n",
    "    for _ in range(n_sims):\n",
    "        seeds = [np.random.choice(list(G.nodes()))]\n",
    "        active = set(seeds)\n",
    "        new_active = set(seeds)\n",
    "        while new_active:\n",
    "            next_active = set()\n",
    "            for u in new_active:\n",
    "                for v in G.neighbors(u):\n",
    "                    if v not in active and np.random.rand() < p:\n",
    "                        next_active.add(v)\n",
    "            active |= next_active\n",
    "            new_active = next_active\n",
    "        spreads.append(len(active))\n",
    "    return np.mean(spreads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f479fea-3542-46b1-94fe-0c5850c14607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_synthetic():\n",
    "    choice = np.random.choice(['ER', 'BA', 'WS'])\n",
    "    n = np.random.randint(120, 200)\n",
    "    if choice == 'ER':\n",
    "        p = np.random.uniform(0.05, 0.15)\n",
    "        return nx.erdos_renyi_graph(n, p)\n",
    "    elif choice == 'BA':\n",
    "        m = np.random.randint(3, 7)\n",
    "        return nx.barabasi_albert_graph(n, m)\n",
    "    else: # WS\n",
    "        k = np.random.randint(4, 10)\n",
    "        beta = np.random.uniform(0.05, 0.25)\n",
    "        return nx.watts_strogatz_graph(n, k, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a40f676-1caa-4366-aa16-a12403204325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_features(G):\n",
    "    if G.number_of_nodes() == 0:\n",
    "        return torch.empty((0, 3), dtype=torch.float)\n",
    "    deg = np.array([d for _, d in G.degree()])\n",
    "    cc  = np.array(list(nx.clustering(G).values()))\n",
    "    avg_nd = np.array(list(nx.average_neighbor_degree(G).values()))\n",
    "    def z(x): return (x - x.mean()) / (x.std() + 1e-8)\n",
    "    X = np.stack([z(deg), z(cc), z(avg_nd)], axis=1)\n",
    "    return torch.tensor(X, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d55085-89c1-4be1-aab8-a6827ad23312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfluenceGNN(torch.nn.Module):\n",
    "    def __init__(self, in_feats=3, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch, edge_weight=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones(edge_index.shape[1], device=x.device)\n",
    "        x = torch.relu(self.conv1(x, edge_index, edge_weight=edge_weight))\n",
    "        x = torch.relu(self.conv2(x, edge_index, edge_weight=edge_weight))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.mlp(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6aa643c-b2c8-4689-8a9c-279d84730a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(num_graphs=1000, epochs=501):\n",
    "    print(\"--- Training Surrogate GNN (to be frozen) ---\")\n",
    "    dataset = []\n",
    "    synthetic_graphs = [sample_synthetic() for _ in range(num_graphs)]\n",
    "    for G in synthetic_graphs:\n",
    "        try:\n",
    "            y = monte_carlo_influence(G, p=0.4, n_sims=400) / G.number_of_nodes()\n",
    "            data = from_networkx(G)\n",
    "            data.x = node_features(G)\n",
    "            data.y = torch.tensor([y], dtype=torch.float)\n",
    "            dataset.append(data)\n",
    "        except Exception as e:\n",
    "            pass # Ignore disconnected graphs\n",
    "    \n",
    "    split = int(0.8 * len(dataset))\n",
    "    train_dataset, test_dataset = dataset[:split], dataset[split:]\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    model = InfluenceGNN()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss = F.mse_loss(out, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            model.eval()\n",
    "            preds, trues = [], []\n",
    "            with torch.no_grad():\n",
    "                for batch in test_loader:\n",
    "                    out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                    preds += out.cpu().tolist()\n",
    "                    trues += batch.y.cpu().tolist()\n",
    "            corr, _ = pearsonr(preds, trues)\n",
    "            print(f\"Epoch {epoch} | Test Corr: {corr:.3f}\")\n",
    "    print(\"--- Surrogate Training Finished ---\")\n",
    "    model.eval() # Freeze model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e4c4695-1685-4573-bab6-a3f9d0d6c343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Surrogate GNN (to be frozen) ---\n",
      "Epoch 0 | Test Corr: -0.669\n",
      "Epoch 100 | Test Corr: 0.959\n",
      "Epoch 200 | Test Corr: 0.962\n",
      "Epoch 300 | Test Corr: 0.969\n",
      "Epoch 400 | Test Corr: 0.973\n",
      "Epoch 500 | Test Corr: 0.975\n",
      "--- Surrogate Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "model = get_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a8f29f-5157-40e6-853b-e1c950f9406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_edge_mappings(G, data):\n",
    "    undirected_edges = sorted([tuple(sorted(e)) for e in G.edges()])\n",
    "    undirected_edge_to_index = {e: i for i, e in enumerate(undirected_edges)}\n",
    "    index_map = {}\n",
    "    ei = data.edge_index.cpu().numpy()\n",
    "    for col in range(ei.shape[1]):\n",
    "        u, v = int(ei[0, col]), int(ei[1, col])\n",
    "        index_map[(u, v)] = col\n",
    "    return undirected_edge_to_index, index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f95781b-b934-426d-91e3-2df6ed5a9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edge_weight(G, w, data, undirected_edge_to_index, index_map):\n",
    "    E_dir = data.edge_index.size(1)\n",
    "    ew = torch.zeros(E_dir, dtype=torch.float32)\n",
    "    for (u, v), idx in index_map.items():\n",
    "        key = tuple(sorted((u, v)))\n",
    "        ew[idx] = w[undirected_edge_to_index[key]]\n",
    "    return ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a377c02-aa59-4584-a41b-2cdc440f6535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_relaxation_optimize(G0, model, lam, steps=200, lr=0.03):\n",
    "    model.eval()\n",
    "    undirected_edges = sorted([tuple(sorted(e)) for e in G0.edges()])\n",
    "    num_edges = len(undirected_edges)\n",
    "    w = torch.full((num_edges,), 0.99, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([w], lr=lr)\n",
    "    \n",
    "    data = from_networkx(G0)\n",
    "    data.x = node_features(G0)\n",
    "    batch = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "    undirected_edge_to_index, index_map = prepare_edge_mappings(G0, data)\n",
    "\n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        ew = make_edge_weight(G0, w, data, undirected_edge_to_index, index_map)\n",
    "        pred = model(data.x, data.edge_index, batch, edge_weight=ew)\n",
    "        loss = -pred + lam * torch.mean(torch.abs(1 - w))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            w.clamp_(0.0, 1.0)\n",
    "    return w.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1f3023-804b-47f5-8b9d-9b715c97cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_prune(G0, w_opt, tau=0.5):\n",
    "    undirected_edges = sorted([tuple(sorted(e)) for e in G0.edges()])\n",
    "    G_pruned = nx.Graph()\n",
    "    G_pruned.add_nodes_from(G0.nodes())\n",
    "    kept_edges = [e for e, val in zip(undirected_edges, w_opt) if val > tau]\n",
    "    G_pruned.add_edges_from(kept_edges)\n",
    "    return G_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b12da65-7f3c-48aa-b8de-0262cfe8a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 10 evaluation graphs.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: DEFINE A CLEAN EVALUATION GRAPH SET\n",
    "eval_graphs = [sample_synthetic() for _ in range(10)]\n",
    "print(f\"Generated {len(eval_graphs)} evaluation graphs.\")\n",
    "\n",
    "# STEP 2: DEFINE LAMBDA SWEEP\n",
    "lambda_list = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "results = {lam: {'edges_kept': [], 'influence': []} for lam in lambda_list}\n",
    "tau = 0.5 # Discretization threshold\n",
    "\n",
    "# STEP 3: REPEAT RELAXATION FOR EACH LAMBDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a08f42ad-5951-46a0-8f2f-3ff81d1e25cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Graph 1/10 (187 nodes, 1262 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.30 | Influence: 0.414\n",
      "  lambda=0.0010 | Edges: 0.30 | Influence: 0.440\n",
      "  lambda=0.0050 | Edges: 0.30 | Influence: 0.415\n",
      "  lambda=0.0100 | Edges: 0.31 | Influence: 0.461\n",
      "  lambda=0.0500 | Edges: 0.33 | Influence: 0.524\n",
      "  lambda=0.1000 | Edges: 0.34 | Influence: 0.560\n",
      "  lambda=0.2000 | Edges: 0.44 | Influence: 0.793\n",
      "  lambda=0.5000 | Edges: 0.77 | Influence: 0.974\n",
      "\n",
      "--- Processing Graph 2/10 (194 nodes, 1721 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.27 | Influence: 0.578\n",
      "  lambda=0.0010 | Edges: 0.26 | Influence: 0.563\n",
      "  lambda=0.0050 | Edges: 0.28 | Influence: 0.602\n",
      "  lambda=0.0100 | Edges: 0.28 | Influence: 0.590\n",
      "  lambda=0.0500 | Edges: 0.32 | Influence: 0.670\n",
      "  lambda=0.1000 | Edges: 0.35 | Influence: 0.779\n",
      "  lambda=0.2000 | Edges: 0.46 | Influence: 0.907\n",
      "  lambda=0.5000 | Edges: 0.76 | Influence: 0.986\n",
      "\n",
      "--- Processing Graph 3/10 (198 nodes, 594 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.48 | Influence: 0.036\n",
      "  lambda=0.0010 | Edges: 0.49 | Influence: 0.032\n",
      "  lambda=0.0050 | Edges: 0.48 | Influence: 0.033\n",
      "  lambda=0.0100 | Edges: 0.49 | Influence: 0.034\n",
      "  lambda=0.0500 | Edges: 0.51 | Influence: 0.042\n",
      "  lambda=0.1000 | Edges: 0.56 | Influence: 0.056\n",
      "  lambda=0.2000 | Edges: 0.62 | Influence: 0.102\n",
      "  lambda=0.5000 | Edges: 0.78 | Influence: 0.414\n",
      "\n",
      "--- Processing Graph 4/10 (186 nodes, 2503 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.23 | Influence: 0.635\n",
      "  lambda=0.0010 | Edges: 0.23 | Influence: 0.638\n",
      "  lambda=0.0050 | Edges: 0.23 | Influence: 0.660\n",
      "  lambda=0.0100 | Edges: 0.24 | Influence: 0.669\n",
      "  lambda=0.0500 | Edges: 0.26 | Influence: 0.702\n",
      "  lambda=0.1000 | Edges: 0.28 | Influence: 0.769\n",
      "  lambda=0.2000 | Edges: 0.35 | Influence: 0.878\n",
      "  lambda=0.5000 | Edges: 0.52 | Influence: 0.965\n",
      "\n",
      "--- Processing Graph 5/10 (166 nodes, 1259 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.23 | Influence: 0.264\n",
      "  lambda=0.0010 | Edges: 0.23 | Influence: 0.245\n",
      "  lambda=0.0050 | Edges: 0.24 | Influence: 0.265\n",
      "  lambda=0.0100 | Edges: 0.23 | Influence: 0.262\n",
      "  lambda=0.0500 | Edges: 0.25 | Influence: 0.309\n",
      "  lambda=0.1000 | Edges: 0.26 | Influence: 0.338\n",
      "  lambda=0.2000 | Edges: 0.35 | Influence: 0.661\n",
      "  lambda=0.5000 | Edges: 0.74 | Influence: 0.977\n",
      "\n",
      "--- Processing Graph 6/10 (197 nodes, 960 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.33 | Influence: 0.196\n",
      "  lambda=0.0010 | Edges: 0.33 | Influence: 0.183\n",
      "  lambda=0.0050 | Edges: 0.35 | Influence: 0.275\n",
      "  lambda=0.0100 | Edges: 0.36 | Influence: 0.294\n",
      "  lambda=0.0500 | Edges: 0.40 | Influence: 0.411\n",
      "  lambda=0.1000 | Edges: 0.43 | Influence: 0.467\n",
      "  lambda=0.2000 | Edges: 0.55 | Influence: 0.630\n",
      "  lambda=0.5000 | Edges: 0.91 | Influence: 0.892\n",
      "\n",
      "--- Processing Graph 7/10 (197 nodes, 394 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.52 | Influence: 0.015\n",
      "  lambda=0.0010 | Edges: 0.53 | Influence: 0.014\n",
      "  lambda=0.0050 | Edges: 0.52 | Influence: 0.014\n",
      "  lambda=0.0100 | Edges: 0.53 | Influence: 0.014\n",
      "  lambda=0.0500 | Edges: 0.53 | Influence: 0.014\n",
      "  lambda=0.1000 | Edges: 0.59 | Influence: 0.016\n",
      "  lambda=0.2000 | Edges: 0.63 | Influence: 0.018\n",
      "  lambda=0.5000 | Edges: 0.71 | Influence: 0.025\n",
      "\n",
      "--- Processing Graph 8/10 (126 nodes, 720 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.27 | Influence: 0.223\n",
      "  lambda=0.0010 | Edges: 0.27 | Influence: 0.245\n",
      "  lambda=0.0050 | Edges: 0.27 | Influence: 0.236\n",
      "  lambda=0.0100 | Edges: 0.28 | Influence: 0.243\n",
      "  lambda=0.0500 | Edges: 0.31 | Influence: 0.314\n",
      "  lambda=0.1000 | Edges: 0.38 | Influence: 0.506\n",
      "  lambda=0.2000 | Edges: 0.53 | Influence: 0.716\n",
      "  lambda=0.5000 | Edges: 0.99 | Influence: 0.957\n",
      "\n",
      "--- Processing Graph 9/10 (125 nodes, 387 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.38 | Influence: 0.039\n",
      "  lambda=0.0010 | Edges: 0.39 | Influence: 0.040\n",
      "  lambda=0.0050 | Edges: 0.38 | Influence: 0.035\n",
      "  lambda=0.0100 | Edges: 0.39 | Influence: 0.037\n",
      "  lambda=0.0500 | Edges: 0.41 | Influence: 0.043\n",
      "  lambda=0.1000 | Edges: 0.47 | Influence: 0.075\n",
      "  lambda=0.2000 | Edges: 0.55 | Influence: 0.200\n",
      "  lambda=0.5000 | Edges: 0.77 | Influence: 0.588\n",
      "\n",
      "--- Processing Graph 10/10 (156 nodes, 608 edges) ---\n",
      "  lambda=0.0005 | Edges: 0.31 | Influence: 0.052\n",
      "  lambda=0.0010 | Edges: 0.32 | Influence: 0.056\n",
      "  lambda=0.0050 | Edges: 0.32 | Influence: 0.065\n",
      "  lambda=0.0100 | Edges: 0.35 | Influence: 0.102\n",
      "  lambda=0.0500 | Edges: 0.38 | Influence: 0.161\n",
      "  lambda=0.1000 | Edges: 0.47 | Influence: 0.344\n",
      "  lambda=0.2000 | Edges: 0.62 | Influence: 0.559\n",
      "  lambda=0.5000 | Edges: 0.92 | Influence: 0.799\n"
     ]
    }
   ],
   "source": [
    "for i, G0 in enumerate(eval_graphs):\n",
    "    print(f\"\\n--- Processing Graph {i+1}/{len(eval_graphs)} ({G0.number_of_nodes()} nodes, {G0.number_of_edges()} edges) ---\")\n",
    "    if G0.number_of_edges() == 0: continue\n",
    "    \n",
    "    # Compute original influence\n",
    "    norm_infl_orig = monte_carlo_influence(G0) / G0.number_of_nodes()\n",
    "    \n",
    "    for lam in lambda_list:\n",
    "        # a. Run continuous relaxation\n",
    "        w_opt = continuous_relaxation_optimize(G0, model, lam=lam)\n",
    "\n",
    "        # b. Convert continuous weights to discrete edges\n",
    "        G_pruned = discrete_prune(G0, w_opt, tau)\n",
    "\n",
    "        # c. Compute TRUE influence\n",
    "        norm_infl_pruned = monte_carlo_influence(G_pruned) / G0.number_of_nodes()\n",
    "\n",
    "        # d. Record results\n",
    "        edges_kept_frac = G_pruned.number_of_edges() / G0.number_of_edges()\n",
    "        results[lam]['edges_kept'].append(edges_kept_frac)\n",
    "        results[lam]['influence'].append(norm_infl_pruned)\n",
    "        print(f\"  lambda={lam:.4f} | Edges: {edges_kept_frac:.2f} | Influence: {norm_infl_pruned:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198afbf8-86ee-437e-8c86-31bece500de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results = {'edges_kept': [], 'influence': []}\n",
    "for lam in lambda_list:\n",
    "    mean_results['edges_kept'].append(np.mean(results[lam]['edges_kept']))\n",
    "    mean_results['influence'].append(np.mean(results[lam]['influence']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a530283-1144-43d3-b5ca-502ee6b5aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_edge_removal_baseline(G0, num_edges_to_keep):\n",
    "    if num_edges_to_keep > G0.number_of_edges():\n",
    "        return G0.copy()\n",
    "    \n",
    "    edges_to_remove = random.sample(list(G0.edges()), G0.number_of_edges() - num_edges_to_keep)\n",
    "    G_baseline = G0.copy()\n",
    "    G_baseline.remove_edges_from(edges_to_remove)\n",
    "    return G_baseline\n",
    "\n",
    "baseline_results = {edges_kept: [] for edges_kept in mean_results['edges_kept']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45d5c921-9e78-41aa-a63d-fe91908e7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for edges_kept_frac in mean_results['edges_kept']:\n",
    "     for G0 in eval_graphs:\n",
    "         if G0.number_of_edges() > 0:\n",
    "             num_edges_to_keep = int(edges_kept_frac * G0.number_of_edges())\n",
    "             G_baseline = random_edge_removal_baseline(G0, num_edges_to_keep)\n",
    "             norm_infl_baseline = monte_carlo_influence(G_baseline) / G0.number_of_nodes()\n",
    "             baseline_results[edges_kept_frac].append(norm_infl_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd021e73-e7fb-4106-b05a-3e264c76afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_baseline_influence = [\n",
    "    np.mean(baseline_results[ek]) if baseline_results[ek] else 0\n",
    "    for ek in mean_results['edges_kept']\n",
    "]\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "# Plot Continuous Relaxation Curve\n",
    "ax.plot(\n",
    "    mean_results['edges_kept'],\n",
    "    mean_results['influence'],\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    label='Continuous Relaxation'\n",
    ")\n",
    "\n",
    "# Plot Baseline Curve\n",
    "ax.plot(\n",
    "    mean_results['edges_kept'],\n",
    "    mean_baseline_influence,\n",
    "    marker='x',\n",
    "    linestyle='--',\n",
    "    label='Random Edge Removal'\n",
    ")\n",
    "\n",
    "# Annotate lambda values\n",
    "for i, lam in enumerate(lambda_list):\n",
    "    ax.annotate(\n",
    "        f\"$\\\\lambda={lam}$\",\n",
    "        (mean_results['edges_kept'][i], mean_results['influence'][i]),\n",
    "        textcoords=\"offset points\",\n",
    "        xytext=(0, 10),\n",
    "        ha='center',\n",
    "        fontsize=9,\n",
    "        color='darkgreen'\n",
    "    )\n",
    "\n",
    "ax.set_title('Sparsity vs. Influence Tradeoff', fontsize=16)\n",
    "ax.set_xlabel('Fraction of Edges Kept', fontsize=12)\n",
    "ax.set_ylabel('Normalized Influence Spread', fontsize=12)\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"sparsityVInfluence.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d6a30-de14-49e7-8366-f08175e593ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
